{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File:           Project_Model  \n",
    "  \n",
    "### Authors:        Brooke McWilliams, James Birch  \n",
    "  \n",
    "### Date Created:   11/19/2023  \n",
    "  \n",
    "### Last Modified:  12/04/2023  \n",
    "  \n",
    "### Description:    Strip features out of audio files using the librosa library and perform CNN modeling using the tensors and keras libraries  \n",
    "<br>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import noisereduce as nr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk through the Crema directory and read each audio file  \n",
    "Extract features from the file for training  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUDIO FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./Crema Dataset/\"\n",
    "\n",
    "wav_data = []\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".wav\"):               \n",
    "        file_path = os.path.join(path, file)\n",
    "        data, sr = librosa.load(file_path, sr=None)\n",
    "        label = (file.split('_')[2])\n",
    "        \n",
    "        if label == 'ANG':\n",
    "            y_s = librosa.effects.time_stretch(data, rate=1)\n",
    "            MEL_Feature = librosa.feature.melspectrogram(y=y_s, sr=sr)\n",
    "            MEL_Feature = tensorflow.image.resize(np.expand_dims(MEL_Feature,axis=-1),(128, 128))\n",
    "        elif label == 'SAD':\n",
    "            y_s = librosa.effects.time_stretch(data, rate=1)\n",
    "            MEL_Feature = librosa.feature.melspectrogram(y=y_s, sr=sr)\n",
    "            MEL_Feature = tensorflow.image.resize(np.expand_dims(MEL_Feature,axis=-1),(128, 128))\n",
    "        elif label == 'DIS':\n",
    "            y_s = librosa.effects.time_stretch(data, rate=1)\n",
    "            MEL_Feature = librosa.feature.melspectrogram(y=y_s, sr=sr)\n",
    "            MEL_Feature = tensorflow.image.resize(np.expand_dims(MEL_Feature,axis=-1),(128, 128))\n",
    "        elif label == 'FEA':\n",
    "            y_s = librosa.effects.time_stretch(data, rate=1)\n",
    "            MEL_Feature = librosa.feature.melspectrogram(y=y_s, sr=sr)\n",
    "            MEL_Feature = tensorflow.image.resize(np.expand_dims(MEL_Feature,axis=-1),(128, 128))\n",
    "        elif label == 'HAP':\n",
    "            y_s = librosa.effects.time_stretch(data, rate=1.3)\n",
    "            MEL_Feature = librosa.feature.melspectrogram(y=y_s, sr=sr)\n",
    "            MEL_Feature = tensorflow.image.resize(np.expand_dims(MEL_Feature,axis=-1),(128, 128))\n",
    "        elif label == 'NEU':\n",
    "            y_s = librosa.effects.time_stretch(data, rate=1.3)\n",
    "            MEL_Feature = librosa.feature.melspectrogram(y=y_s, sr=sr)\n",
    "            MEL_Feature = tensorflow.image.resize(np.expand_dims(MEL_Feature,axis=-1),(128, 128))\n",
    "        \n",
    "    wav_data.append([file, label, MEL_Feature])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUDIO TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_length(time_series_list, length):\n",
    "    n = len(time_series_list)\n",
    "    for i in range(n):\n",
    "        audio_length = len(time_series_list[i])\n",
    "        if audio_length < length:\n",
    "            time_series_list[i] = np.append(time_series_list[i], [0 for i in range(length-audio_length)])\n",
    "        else:\n",
    "            time_series_list[i] = np.array(time_series_list[i][:length])\n",
    "\n",
    "def check_for_nan(l):\n",
    "    for x in l:\n",
    "        if str(x) == 'nan':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def adjust_length(time_series_list, length):\n",
    "    n = len(time_series_list)\n",
    "    for i in range(n):\n",
    "        audio_length = len(time_series_list[i])\n",
    "        if audio_length < length:\n",
    "            time_series_list[i] = np.append(time_series_list[i], [0 for i in range(length-audio_length)])\n",
    "        else:\n",
    "            time_series_list[i] = np.array(time_series_list[i][:length])  \n",
    "\n",
    "def feature_extraction_1D(data, sampling_rate):\n",
    "\n",
    "    # Zero Crossing rate\n",
    "    features = librosa.feature.zero_crossing_rate(y=data)\n",
    "\n",
    "    # Energy\n",
    "    features = np.append(features, librosa.feature.rms(y=data), axis=1)\n",
    "\n",
    "    # Mel-frequency cepstral coefficient\n",
    "    l = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=13), axis=0).reshape(1, 106)\n",
    "    features = np.append(features, l, axis=1)\n",
    "    \n",
    "    # Spectral Centroid\n",
    "    features = np.append(features, librosa.feature.spectral_centroid(y=data, sr=sampling_rate), axis=1)\n",
    "    \n",
    "    # Spectral Bandwidth\n",
    "    features = np.append(features, librosa.feature.spectral_bandwidth(y=data, sr=sampling_rate), axis=1)\n",
    "    \n",
    "    # Spectral Flatness\n",
    "    features = np.append(features, librosa.feature.spectral_flatness(y=data), axis=1)\n",
    "    \n",
    "    # Spectral Rolloff maximum frequencies\n",
    "    features = np.append(features, librosa.feature.spectral_rolloff(y=data, sr=sampling_rate), axis=1)\n",
    "    \n",
    "    # Spectral Rolloff minimum frequencies\n",
    "    features = np.append(features, librosa.feature.spectral_rolloff(y=data, sr=sampling_rate, roll_percent=0.01), axis=1)\n",
    "    \n",
    "    return np.array(features)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./Crema Dataset/\"\n",
    "\n",
    "wav_data = [] \n",
    "labelList = [] \n",
    "sampling_rate = 18000 \n",
    "\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".wav\"):               \n",
    "        file_path = os.path.join(path, file)\n",
    "        data, sr = librosa.load(file_path, sr=sampling_rate)\n",
    "        label = (file.split('_')[2])\n",
    "\n",
    "        reduced_noise = nr.reduce_noise(y=data, sr=sampling_rate)\n",
    "        if not check_for_nan(reduced_noise):\n",
    "            data = reduced_noise\n",
    "            \n",
    "        wav_data.append(data)\n",
    "        labelList.append(label)\n",
    "\n",
    "n = len(wav_data)\n",
    "adjust_length(wav_data, 3*sampling_rate)\n",
    "wav_data = np.array(wav_data)\n",
    "\n",
    "data_features_extracted_1D = []\n",
    "for i in range(n):\n",
    "    data_features_extracted_1D.append(np.squeeze(np.append(feature_extraction_1D(wav_data[i], sampling_rate), labelList[i])))\n",
    "\n",
    "data_features_extracted_1D = np.array(data_features_extracted_1D)\n",
    "print(data_features_extracted_1D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Dropout, MaxPooling1D, Flatten, Dense, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model Section\n",
    "Build the CNN model for training  \n",
    "Top val_accuracy = 63%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_test(num_label, inputShape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=256, kernel_size=3, padding='same', activation='relu', input_shape=(128,128)))\n",
    "\n",
    "    model.add(Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2, padding='same', strides=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2, padding='same', strides=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPooling1D(pool_size=2, padding='same', strides=2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_label, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing and encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [item[2] for item in wav_data]\n",
    "y = [item[1] for item in wav_data]\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "num_label = len(pd.unique(y))\n",
    "y = to_categorical(y, num_classes=6)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Shape of X1_train: {X_train.shape}\\n\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\\n\")\n",
    "print(f\"Shape of X1_test: {X_test.shape}\\n\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\\n\")\n",
    "print(f\"Number of labels: {num_label}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send training data to model function and return compiled CNN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = build_model(X_train, y_train, X_test, y_test, num_label)\n",
    "\n",
    "\n",
    "model1.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "acc1 = model1.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Model Accuracy: {acc1[1]:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Model Section  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_test(num_label, train):\n",
    "    inputShape = (train.shape[1], 1)\n",
    "\n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(Conv1D(input_shape=inputShape,filters=64,kernel_size=3,padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "    model.add(Conv1D(filters=64,kernel_size=3,padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(Conv1D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling1D(pool_size=2,strides=2))\n",
    "    \n",
    "    model.add(Conv1D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPooling1D(pool_size=2,strides=2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=4096,activation=\"relu\"))\n",
    "    model.add(Dense(num_label, activation=\"softmax\"))\n",
    "\n",
    "    opt = Adam(learning_rate=0.0001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.array((data_features_extracted_1D[:, :-1]))\n",
    "y = np.array(labelList)\n",
    "X = X.astype(float)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "num_label = len(pd.unique(y))\n",
    "y = to_categorical(y, num_classes=6)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"Shape of X1_train: {X_train.shape}\\n\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\\n\")\n",
    "print(f\"Shape of X1_test: {X_test.shape}\\n\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\\n\")\n",
    "print(f\"Number of labels: {num_label}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = build_model_test(num_label, X_train)\n",
    "\n",
    "model1.fit(X_train, y_train, epochs=150, batch_size=64, use_multiprocessing=True, validation_data=(X_test, y_test))\n",
    "acc1 = model1.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Model Accuracy: {acc1[1]:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
